---
description: PostgreSQL integration via sqlx and yft-service-sdk
alwaysApply: false
---
# PostgreSQL (sqlx) integration

PostgreSQL is used via `sqlx` in this project. This rule describes how to:

- Enable PostgreSQL integration in a service via `yft-service-sdk` feature flags.
- Configure the connection string in settings.
- Obtain a `PgPool` from `ServiceContext`.
- Organize models and repositories under `src/postgres/...`.
- Create and manage migrations via `sqlx migrate`.

The goal is to keep DB access consistent with the layered architecture
(network models → DTOs → flows → repositories → data store models).

---

## 1. Enabling PostgreSQL for a service

To connect a service to PostgreSQL:

1. Enable the `postgresql` feature in `yft-service-sdk` in `Cargo.toml`:

```toml
[dependencies]
yft-service-sdk = { path = "yft-service-sdk", features = ["postgresql", /* other features */] }
sqlx = { version = "X.Y", features = ["runtime-tokio-rustls", "postgres"] }
```

2. Add the connection setting to the settings model in `src/settings.rs`:

```rust
#[derive(
    Debug,
    Clone,
    serde::Serialize,
    serde::Deserialize,
    yft_service_sdk::macros::SdkSettingsTraits,
    yft_service_sdk::macros::AutoGenerateSettingsTraits,
    yft_service_sdk::external::my_settings_reader::SettingsModel,
)]
pub struct SettingsModel {
    pub logs_host_port: String,
    pub my_no_sql_writer: String,
    pub my_no_sql_tcp_reader: String,

    // PostgreSQL connection string (sqlx)
    pub sqlx_connection: String,
}
```

> The `SettingsReader` type generated by the macros is expected to implement
> the `SqlxSettings` trait (from the SDK), which exposes connection details
> for `get_db_pool`.

---

## 2. Getting a PgPool from ServiceContext

Once the feature is enabled and settings are in place, `ServiceContext`
exposes a helper to build a PostgreSQL pool:

```rust
#[cfg(feature = "postgresql")]
pub async fn get_db_pool<T: crate::SqlxSettings>(
    &self,
    connection_settings: &T,
    config_callback: impl Fn(&mut sqlx::postgres::PgPoolOptions) -> sqlx::postgres::PgPoolOptions,
) -> sqlx::Pool<sqlx::postgres::Postgres> {
    // implementation in yft-service-sdk
}
```

Typical usage in a service (e.g. in some factory or in `AppContext::new`):

```rust
use std::sync::Arc;
use sqlx::postgres::PgPool;
use yft_service_sdk::ServiceContext;
use crate::settings::SettingsReader;

pub struct PostgresDeps {
    pub pool: Arc<PgPool>,
}

impl PostgresDeps {
    pub async fn new(settings: &Arc<SettingsReader>, sc: &ServiceContext) -> Self {
        let pool = Arc::new(sc.get_db_pool(settings.as_ref(), |opts| opts.clone()).await);

        Self { pool }
    }
}
```

Rules:
- Always get the DB pool from `ServiceContext::get_db_pool` – do not create
  `PgPool` manually with `PgPoolOptions` in services.
- The `config_callback` allows customizing pool options (max connections, timeouts, etc.).
  When unsure, you can simply pass `|opts| opts.clone()` as in the example.
- The resulting `PgPool` is usually wrapped in `Arc<PgPool>` for sharing between repositories.

---

## 3. Folder structure for models and repositories

All PostgreSQL models and repositories are organized under `src/postgres/<table_name>/`.

For each table or logical aggregate, use the following structure:

```text
src/
  postgres/
    accounts/
      accounts_model.rs
      accounts_repo.rs
    orders/
      orders_model.rs
      orders_repo.rs
    ...
```

Convention:
- `<table_name>_model.rs` – data store model(s) representing rows in the table.
- `<table_name>_repo.rs` – repository with methods for interacting with that table
  using `sqlx`.

> The exact table name and file name can vary, but keep it consistent:
> `<name>_model.rs` and `<name>_repo.rs` inside `src/postgres/<name>/`.

---

## 4. Repository pattern (PgPool in a struct)

Each repository is a struct holding `Arc<PgPool>` and providing methods
for queries and commands.

Example repository structure:

```rust
use std::sync::Arc;
use sqlx::postgres::PgPool;

pub struct AccountsRepository {
    pub pool: Arc<PgPool>,
}

impl AccountsRepository {
    pub fn new(pool: Arc<PgPool>) -> Self {
        Self { pool }
    }

    // Example method: customize per table
    // pub async fn get_by_id(&self, id: i64) -> Result<Option<AccountModel>, sqlx::Error> {
    //     sqlx::query_as!(
    //         AccountModel,
    //         r#"
    //             SELECT id, name, created_at
    //             FROM accounts
    //             WHERE id = $1
    //         "#,
    //         id,
    //     )
    //     .fetch_optional(self.pool.as_ref())
    //     .await
    // }
}
```

Rules:
- The repository struct MUST own an `Arc<PgPool>`, not a raw `PgPool`.
- Repository methods are free to define any queries they need; there is no enforced method set.
- Keep business logic out of the repository – it should only handle data access
  and basic mapping to/from data store models.

---

## 5. Wiring repositories in AppContext

Repositories are created and stored in `AppContext::new` so that flows can use them.

Example:

```rust
use std::sync::Arc;
use sqlx::postgres::PgPool;
use crate::postgres::accounts::accounts_repo::AccountsRepository;

#[derive(Clone)]
pub struct AppContext {
    pub db_pool: Arc<PgPool>,
    pub accounts_repo: Arc<AccountsRepository>,
    // ... other repos and dependencies
}

impl AppContext {
    pub async fn new(
        sc: &ServiceContext,
        settings_reader: Arc<SettingsReader>,
    ) -> Self {
        let db_pool = Arc::new(sc.get_db_pool(settings_reader.as_ref(), |opts| opts.clone()).await);

        let accounts_repo = Arc::new(AccountsRepository::new(db_pool.clone()));

        Self {
            db_pool,
            accounts_repo,
            // ... initialize other repositories
        }
    }
}
```

Rules:
- All repositories must be created in `AppContext::new` (or a dedicated factory used by it).
- Controllers/handlers MUST NOT create repositories directly.
- Flows access data only through repositories (or higher-level services that wrap them).

---

## 6. Migrations via sqlx

Schema changes are handled via `sqlx` migrations.

### 6.1. Creating a new migration

Use the `sqlx` CLI command from the service crate root:

```bash
sqlx migrate add table_name
```

This generates a new migration file in the migrations directory, typically:

```text
migrations/
  20251122134709_table_name.sql
```

(The timestamp prefix will be different, but the pattern is:
`<YYYYMMDDHHMMSS>_table_name.sql`.)

### 6.2. Writing the migration

Inside the generated `.sql` file, write the SQL representation of what you
are doing in the code (models and repositories).

Example (for creating a table):

```sql
-- 20251122134709_table_name.sql

CREATE TABLE accounts (
    id BIGSERIAL PRIMARY KEY,
    name TEXT NOT NULL,
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW()
);
```

If you alter an existing table (add column, change index, etc.),
reflect exactly those changes in the migration file.

Rules:
- Every structural change to PostgreSQL tables must be backed by a migration.
- The **code** (models/repositories) and **migrations** must stay in sync:
  - If you add a column in the model, update the table via migration.
  - If you drop or rename a column in the table, update models and repositories accordingly.
- Do not manually edit old migrations that have already been applied to shared environments
  (prod, UAT). Add new migrations instead.

### 6.3. Running migrations

Running migrations is typically done via `sqlx migrate run` (or via CI/deployment scripts),
and is outside the scope of Cursor code editing. However, when adding new tables or columns,
always remember to include a matching migration so the database schema matches the Rust models.

---

## 7. Layering rules for PostgreSQL access

- **Network layer (HTTP/gRPC)**:
  - MUST NOT access `PgPool` or repositories directly.
  - Works only with DTOs and flows.

- **Flows (business logic)**:
  - Use repositories exposed from `AppContext` for data access.
  - Do not embed SQL queries directly in flow functions.

- **Repositories (data access layer)**:
  - Own `Arc<PgPool>` and contain all `sqlx` queries.
  - Map rows to data store models and (optionally) to DTOs when needed.
  - Are created in `AppContext::new` and injected into flows via `AppContext`.

- **Migrations**:
  - Represent the authoritative schema for tables.
  - Must match the expectations of repository queries and data store models.

This keeps PostgreSQL integration consistent, predictable, and aligned with the overall architecture.
